{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bd525c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2b119d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "from itertools import repeat\n",
    "from collections import defaultdict\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "from helpers.extractFeature import extractFeature\n",
    "from helpers.matching import calHammingDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "623d585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CASIA1_DIR = \"../input/CASIA1\"\n",
    "N_IMAGES = 7\n",
    "\n",
    "eyelashes_thresholds = np.linspace(start=10, stop=250, num=25)\n",
    "thresholds = np.linspace(start=0.0, stop=1.0, num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6fee68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_func_extract_feature(args):\n",
    "    im_filename, eyelashes_thres, use_multiprocess = args\n",
    "\n",
    "    template, mask, im_filename = extractFeature(\n",
    "        im_filename=im_filename,\n",
    "        eyelashes_thres=eyelashes_thres,\n",
    "        use_multiprocess=use_multiprocess,\n",
    "    )\n",
    "    return template, mask, im_filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29c2d858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_func_calHammingDist(args):\n",
    "    template1, mask1, template2, mask2 = args\n",
    "    dist = calHammingDist(template1, mask1, template2, mask2)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ef6cd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of identities: 109\n"
     ]
    }
   ],
   "source": [
    "# Get identities of CASIA1 dataset\n",
    "identities = glob(os.path.join(CASIA1_DIR, \"**\"))\n",
    "identities = sorted([os.path.basename(identity) for identity in identities])\n",
    "n_identities = len(identities)\n",
    "print(\"Number of identities:\", n_identities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "287b73d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image files: 756\n"
     ]
    }
   ],
   "source": [
    "# Construct a dictionary of files\n",
    "files_dict = {}\n",
    "image_files = []\n",
    "\n",
    "for identity in identities:\n",
    "    files = glob(os.path.join(CASIA1_DIR, identity, \"*.*\"))\n",
    "    shuffle(files)\n",
    "    files_dict[identity] = files[:N_IMAGES]\n",
    "    image_files += files[:N_IMAGES]\n",
    "\n",
    "n_image_files = len(image_files)\n",
    "print(\"Number of image files:\", n_image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b889390a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "ground_truth = np.zeros([n_image_files, n_image_files], dtype=int)\n",
    "for i in range(ground_truth.shape[0]):\n",
    "    for j in range(ground_truth.shape[1]):\n",
    "        if i//N_IMAGES == j//N_IMAGES:\n",
    "            ground_truth[i, j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4bcfb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [50:46<00:00, 121.86s/it]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate parameters\n",
    "pools = Pool(processes=cpu_count())\n",
    "best_results = []\n",
    "for eye_threshold in tqdm(eyelashes_thresholds, total=len(eyelashes_thresholds)):\n",
    "    # Extract features\n",
    "    args = zip(image_files, repeat(eye_threshold), repeat(False))\n",
    "    features = list(pools.map(pool_func_extract_feature, args))\n",
    "\n",
    "    # Calculate the distances\n",
    "    args = []\n",
    "    for i in range(n_image_files):\n",
    "        for j in range(n_image_files):\n",
    "            if i>=j:\n",
    "                continue\n",
    "            arg = (features[i][0], features[i][1], features[j][0], features[j][1])\n",
    "            args.append(arg)\n",
    "    distances = pools.map(pool_func_calHammingDist, args)\n",
    "\n",
    "    # Construct a distance matrix\n",
    "    k = 0\n",
    "    dist_mat = np.zeros([n_image_files, n_image_files])\n",
    "    for i in range(n_image_files):\n",
    "        for j in range(n_image_files):\n",
    "            if i<j:\n",
    "                dist_mat[i, j] = distances[k]\n",
    "                k += 1\n",
    "            elif i>j:\n",
    "                dist_mat[i, j] = dist_mat[j, i]\n",
    "\n",
    "    # Metrics\n",
    "    accuracies, precisions, recalls, fscores = [], [], [], []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        decision_map = (dist_mat<=threshold).astype(int)\n",
    "        accuracy = (decision_map==ground_truth).sum() / ground_truth.size\n",
    "        precision = (ground_truth*decision_map).sum() / decision_map.sum()\n",
    "        recall = (ground_truth*decision_map).sum() / ground_truth.sum()\n",
    "        fscore = 2*precision*recall / (precision+recall)\n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        fscores.append(fscore)\n",
    "\n",
    "    # Save the best result\n",
    "    best_fscore = max(fscores)\n",
    "    best_threshold = thresholds[fscores.index(best_fscore)]\n",
    "    best_results.append((eye_threshold, best_threshold, best_fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "591a6065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the final best result\n",
    "eye_thresholds = [item[0] for item in best_results]\n",
    "thresholds = [item[1] for item in best_results]\n",
    "fscores = [item[2] for item in best_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "404b039e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum fscore: 0.9367588932806323\n",
      "Best eye_threshold: 80.0\n",
      "Best threshold: 0.4040404040404041\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum fscore:\", max(fscores))\n",
    "print(\"Best eye_threshold:\", eye_thresholds[fscores.index(max(fscores))])\n",
    "print(\"Best threshold:\", thresholds[fscores.index(max(fscores))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dbb641",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch] *",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
